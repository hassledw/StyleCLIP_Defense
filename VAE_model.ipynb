{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE (Variational Autoencoder) for Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCelebrityDataset(Dataset):\n",
    "    '''\n",
    "    This is the Dataset class for the Celebrity data. It's meant to conform\n",
    "    to PyTorch's structure with the DataLoader. Typically, Datasets are premade,\n",
    "    but this allows for customization.\n",
    "    '''\n",
    "    def __init__(self, data_dir, celebrity, idx, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.celebrity = celebrity\n",
    "        self.transform = transform\n",
    "        self.idx = idx # keeps track of celebrity numerical value\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.image_paths, self.labels = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        '''\n",
    "        Interface method, called in the constructor of DataLoader (I think)\n",
    "        This traverses through the ./data folder to assign X and y data to respective\n",
    "        arrays.\n",
    "\n",
    "        Returns the image_paths and numerical_labels (classes in a numeric encoding)\n",
    "        '''\n",
    "        fpath = f\"{self.data_dir}\"\n",
    "        sub_folders = [item for item in os.listdir(fpath) if os.path.isdir(os.path.join(fpath, item))]\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        numerical_labels = []\n",
    "\n",
    "        for image in os.listdir(fpath):\n",
    "            fpath_i = f\"{self.data_dir}/{image}\"\n",
    "            image_paths.append(fpath_i)\n",
    "            labels.append(f\"{self.celebrity}\")\n",
    "            numerical_labels.append(self.idx)\n",
    "                \n",
    "        # print(image_paths)\n",
    "        # print(labels)\n",
    "        \n",
    "        return image_paths, numerical_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns the length of the dataset.\n",
    "        '''\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        gets the item in a Dataset by index. Called by iterators.\n",
    "        '''\n",
    "        # Load an image and its label based on the index 'idx'.\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            # print(image.shape)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataloaders:  14\n",
      "Testing Dataloaders:  14\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "fpath_train = \"./data/train\"\n",
    "fpath_val = \"./data/val\"\n",
    "sub_folders_train = [item for item in os.listdir(fpath_train) if os.path.isdir(os.path.join(fpath_train, item))]\n",
    "sub_folders_val = [item for item in os.listdir(fpath_val) if os.path.isdir(os.path.join(fpath_val, item))]\n",
    "dataloader_arr_train = []\n",
    "dataloader_arr_test = []\n",
    "batch_size = 2\n",
    "\n",
    "# loops through all the celebrities, creates their own dataset (important for labeling)\n",
    "for idx, celebrity_folder in enumerate(sub_folders_val):\n",
    "    #print(celebrity_folder)\n",
    "    dataset_train_celeb = SingleCelebrityDataset(data_dir=f\"{fpath_train}/{celebrity_folder}\", celebrity=celebrity_folder, idx=idx, transform=transform)\n",
    "    dataset_val_celeb = SingleCelebrityDataset(data_dir=f\"{fpath_val}/{celebrity_folder}\", celebrity=celebrity_folder, idx=idx, transform=transform)\n",
    "    dataloader_arr_train.append(DataLoader(dataset_train_celeb, batch_size=batch_size, shuffle=True))\n",
    "    dataloader_arr_test.append(DataLoader(dataset_val_celeb, batch_size=batch_size, shuffle=True))\n",
    "\n",
    "print(\"Training Dataloaders: \", len(dataloader_arr_train))\n",
    "print(\"Testing Dataloaders: \", len(dataloader_arr_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
